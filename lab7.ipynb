{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46804820-34fe-4439-bb36-b082a2fa7540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata...\n",
      "Extracting MFCC features...\n",
      "Preparing data...\n",
      "Training Random Forest with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Evaluating tuned Random Forest...\n",
      "\n",
      "Accuracy on test set: 0.55\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.78      0.70      0.74        10\n",
      "         Low       0.67      0.33      0.44         6\n",
      "      Medium       0.25      0.50      0.33         4\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.56      0.51      0.50        20\n",
      "weighted avg       0.64      0.55      0.57        20\n",
      "\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 91}\n",
      "\n",
      "Benchmarking other classifiers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saath\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "          Model  Train Accuracy  Test Accuracy\n",
      "0           SVM        0.392405           0.60\n",
      "1  DecisionTree        1.000000           0.60\n",
      "2  RandomForest        1.000000           0.50\n",
      "3      AdaBoost        0.835443           0.45\n",
      "4    NaiveBayes        0.582278           0.50\n",
      "5           MLP        0.405063           0.25\n",
      "6       XGBoost        1.000000           0.60\n",
      "7      CatBoost        1.000000           0.50\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Step 1: Load and preprocess audio paths and labels\n",
    "def load_audio_metadata(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df[\"File Path\"].tolist(), df[\"Classification\"].tolist()\n",
    "\n",
    "# Step 2: Extract MFCC features from audio files\n",
    "def extract_mfcc_features(paths, labels, n_mfcc=13, sr=22050, duration=3):\n",
    "    features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for path, label in zip(paths, labels):\n",
    "        try:\n",
    "            y, _ = librosa.load(path, sr=sr, duration=duration)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "            mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "            features.append(mfcc_mean)\n",
    "            valid_labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(features), pd.Series(valid_labels)\n",
    "\n",
    "# Step 3: Encode labels and split data\n",
    "def prepare_data(X, y, test_size=0.2, random_state=42):\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    return train_test_split(X, y_encoded, test_size=test_size, random_state=random_state), le\n",
    "\n",
    "# Step 4: Train Random Forest with hyperparameter tuning\n",
    "def train_random_forest(X_train, y_train):\n",
    "    model = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "    param_dist = {\n",
    "        \"n_estimators\": randint(50, 300),\n",
    "        \"max_depth\": randint(5, 50),\n",
    "        \"min_samples_split\": randint(2, 20),\n",
    "        \"min_samples_leaf\": randint(1, 10),\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "    }\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=100,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    return search.best_estimator_, search\n",
    "\n",
    "# Step 5: Evaluate a model\n",
    "def evaluate_model(model, X_test, y_test, label_encoder):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"\\nAccuracy on test set:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Step 6: Benchmark multiple classifiers\n",
    "def benchmark_models(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"SVM\": SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=42),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(class_weight=\"balanced\", random_state=42),\n",
    "        \"RandomForest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "        \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "        \"NaiveBayes\": GaussianNB(),\n",
    "        \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"mlogloss\", random_state=42),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "            \"Test Accuracy\": accuracy_score(y_test, y_test_pred)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Step 7: Run the full pipeline\n",
    "def run_audio_classification_pipeline(csv_path=\"classified_audios.csv\"):\n",
    "    print(\"Loading metadata...\")\n",
    "    paths, labels = load_audio_metadata(csv_path)\n",
    "\n",
    "    print(\"Extracting MFCC features...\")\n",
    "    X, y = extract_mfcc_features(paths, labels)\n",
    "\n",
    "    print(\"Preparing data...\")\n",
    "    (X_train, X_test, y_train, y_test), le = prepare_data(X, y)\n",
    "\n",
    "    print(\"Training Random Forest with hyperparameter tuning...\")\n",
    "    best_rf_model, search = train_random_forest(X_train, y_train)\n",
    "\n",
    "    print(\"Evaluating tuned Random Forest...\")\n",
    "    evaluate_model(best_rf_model, X_test, y_test, le)\n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    print(\"\\nBenchmarking other classifiers...\")\n",
    "    results_df = benchmark_models(X_train, X_test, y_train, y_test)\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    print(results_df)\n",
    "\n",
    "# Execute\n",
    "run_audio_classification_pipeline(\"classified_audios.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
